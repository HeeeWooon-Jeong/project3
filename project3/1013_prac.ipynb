{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTCrd-Hnql84",
        "outputId": "ee8ef170-c23d-499d-fbbe-63ce88bc388b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOjC_vPTpag_",
        "outputId": "51c8dbb9-c409-40e8-9213-6e09c471c613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                      url        type\n",
            "0                                        br-icloud.com.br    phishing\n",
            "1                     mp3raid.com/music/krizz_kaliko.html      benign\n",
            "2                         bopsecrets.org/rexroth/cr/1.htm      benign\n",
            "3       http://www.garage-pirenne.be/index.php?option=...  defacement\n",
            "4       http://adventure-nicaragua.net/index.php?optio...  defacement\n",
            "...                                                   ...         ...\n",
            "651176            xbox360.ign.com/objects/850/850402.html    phishing\n",
            "651177       games.teamxbox.com/xbox-360/1860/Dead-Space/    phishing\n",
            "651178         www.gamespot.com/xbox360/action/deadspace/    phishing\n",
            "651179      en.wikipedia.org/wiki/Dead_Space_(video_game)    phishing\n",
            "651180          www.angelfire.com/goth/devilmaycrytonite/    phishing\n",
            "\n",
            "[651181 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np                                              # 넘파이\n",
        "import pandas as pd                                             # 판다스\n",
        "from matplotlib import pyplot as plt                            # 파이플랏\n",
        "import chardet                                                  # 다음으로, \"chardet\"를 사용하여 문자열의 인코딩을 감지 아랍어 포함되어있음\n",
        "import numpy as np                                              # 넘파이 사용\n",
        "import warnings                                                 # 경고 무시\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from sklearn.model_selection import train_test_split            # 트레인 테스트 분리\n",
        "import tensorflow as tf                                         # 텐서 플로우\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer       # Keras의 Tokenizer 클래스를 사용하기 위해 인스턴스를 생성합니다.\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 파일의 인코딩을 ISO-8859-1로 지정\n",
        "data = pd.read_csv('./drive/MyDrive/딥러닝/data/malicious_phish.csv', encoding='ISO-8859-1')\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 타입의 총 개수\n",
        "benign_count = data[data['type'] == 'benign'].shape[0]\n",
        "defacement_count = data[data['type'] == 'defacement'].shape[0]\n",
        "malware_count = data[data['type'] == 'malware'].shape[0]\n",
        "phishing_count = data[data['type'] == 'phishing'].shape[0]\n",
        "\n",
        "# 결과 출력\n",
        "benign_count, defacement_count, malware_count, phishing_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh2a9ETYrpZF",
        "outputId": "dd3f09f2-ada4-4325-e7ec-b2747dfdb62e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(428103, 96457, 32520, 94101)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "X = data['url']\n",
        "y = data['type']\n",
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZY9QJvstyqE",
        "outputId": "401c2921-9134-4e22-a79e-cc2b9ab717bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0                                          br-icloud.com.br\n",
              " 1                       mp3raid.com/music/krizz_kaliko.html\n",
              " 2                           bopsecrets.org/rexroth/cr/1.htm\n",
              " 3         http://www.garage-pirenne.be/index.php?option=...\n",
              " 4         http://adventure-nicaragua.net/index.php?optio...\n",
              "                                 ...                        \n",
              " 651176              xbox360.ign.com/objects/850/850402.html\n",
              " 651177         games.teamxbox.com/xbox-360/1860/Dead-Space/\n",
              " 651178           www.gamespot.com/xbox360/action/deadspace/\n",
              " 651179        en.wikipedia.org/wiki/Dead_Space_(video_game)\n",
              " 651180            www.angelfire.com/goth/devilmaycrytonite/\n",
              " Name: url, Length: 651181, dtype: object,\n",
              " 0           phishing\n",
              " 1             benign\n",
              " 2             benign\n",
              " 3         defacement\n",
              " 4         defacement\n",
              "              ...    \n",
              " 651176      phishing\n",
              " 651177      phishing\n",
              " 651178      phishing\n",
              " 651179      phishing\n",
              " 651180      phishing\n",
              " Name: type, Length: 651181, dtype: object)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size = 0.3,\n",
        "                                                    random_state = 10)"
      ],
      "metadata": {
        "id": "5asij7R-zJ3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u3R6lY9pzvTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "from tensorflow.keras import Sequential # 뼈대가 되는 부분\n",
        "from tensorflow.keras.layers import Dense # 층을 쌓아주는 부분"
      ],
      "metadata": {
        "id": "EUEUkXv00uWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4758yETv6EU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 인코딩\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# 텍스트 데이터를 시퀀스로 변환\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X) # Tokenizer를 학습 데이터 X에 맞춥니다. 이를 통해 Tokenizer는 학습 데이터에 등장하는 단어들을 기반으로 단어 사전을 구축합니다. 각 단어에 고유한 정수 인덱스를 할당합니다.\n",
        "X = tokenizer.texts_to_sequences(X) # 학습된 Tokenizer를 사용하여 텍스트 데이터인 X를 정수 시퀀스로 변환합니다. 각 단어는 이제 그에 해당하는 정수로 대체되어 있습니다. 이렇게 변환된 시퀀스는 모델의 입력으로 사용됩니다.\n",
        "\n",
        "# 시퀀스 길이를 일치시키기 위한 패딩\n",
        "X = pad_sequences(X) # 함수를 사용하여 시퀀스 데이터의 길이를 맞춰줍니다.\n",
        "\n",
        "# 데이터 분리 (훈련 데이터와 테스트 데이터)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 정의\n",
        "model = keras.Sequential([\n",
        "    layers.Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=32, input_length=X.shape[1]),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# 모델 평가\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "id": "XQ79EC5_5YVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 가상의 데이터 프레임 (실제 데이터로 대체해야 함)\n",
        "data = pd.read_csv('./drive/MyDrive/딥러닝/data/malicious_phish.csv', encoding='ISO-8859-1')\n",
        "\n",
        "# 데이터 전처리\n",
        "X = data['url']\n",
        "y = data['type']\n",
        "\n",
        "# 레이블 인코딩\n",
        "# 정답데이터의 타입이 4개 이므로 레이블 인코딩으로 모델이 학습하기 좋게 숫자로 변경\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# tokenizer 사용하여 텍스트 데이터를 시퀀스로 변환\n",
        "# 일반적으로 공백이나 구두점을 기준으로 단어를 분리\n",
        "tokenizer = Tokenizer(num_words=10000)  # 등장 빈도수가 높은 상위 10,000개의 단어만 사용하여 학습 진행\n",
        "tokenizer.fit_on_texts(X) # X에 대한 단어사전 구축\n",
        "X = tokenizer.texts_to_sequences(X) #\n",
        "X = pad_sequences(X, maxlen=100)  # 시퀀스 길이를 100으로 맞춤\n",
        "\n",
        "# 데이터 분리 (훈련 데이터와 테스트 데이터)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 정의\n",
        "model = keras.Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=32, input_length=100),\n",
        "    LSTM(64),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 모델 훈련\n",
        "num_epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, verbose=1)\n",
        "# 12:00 시작\n",
        "# 모델 평가\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test accuracy: {test_accuracy * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZEpBXph_8zW",
        "outputId": "59a02884-725f-4c35-8f97-27442309539e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16280/16280 [==============================] - 1116s 68ms/step - loss: 0.1509 - accuracy: 0.9451\n",
            "Epoch 2/10\n",
            "16280/16280 [==============================] - 1095s 67ms/step - loss: 0.1054 - accuracy: 0.9604\n",
            "Epoch 3/10\n",
            "16280/16280 [==============================] - 1082s 66ms/step - loss: 0.0963 - accuracy: 0.9635\n",
            "Epoch 4/10\n",
            "16280/16280 [==============================] - 1079s 66ms/step - loss: 0.0910 - accuracy: 0.9653\n",
            "Epoch 5/10\n",
            "16280/16280 [==============================] - 1080s 66ms/step - loss: 0.0870 - accuracy: 0.9667\n",
            "Epoch 6/10\n",
            "16280/16280 [==============================] - 1088s 67ms/step - loss: 0.0839 - accuracy: 0.9678\n",
            "Epoch 7/10\n",
            "16280/16280 [==============================] - 1087s 67ms/step - loss: 0.0812 - accuracy: 0.9689\n",
            "Epoch 8/10\n",
            "16280/16280 [==============================] - 1084s 67ms/step - loss: 0.0788 - accuracy: 0.9697\n",
            "Epoch 9/10\n",
            "16280/16280 [==============================] - 1089s 67ms/step - loss: 0.0769 - accuracy: 0.9703\n",
            "Epoch 10/10\n",
            "16280/16280 [==============================] - 1093s 67ms/step - loss: 0.0752 - accuracy: 0.9710\n",
            "4070/4070 [==============================] - 74s 18ms/step - loss: 0.1111 - accuracy: 0.9610\n",
            "Test accuracy: 96.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 URL 주소\n",
        "new_url = [\"https://www.youtube.com\"]  # 여기에 테스트하려는 URL 주소를 추가하세요\n",
        "\n",
        "# 텍스트 데이터를 시퀀스로 변환\n",
        "new_url_sequences = tokenizer.texts_to_sequences(new_url)\n",
        "new_url_sequences = pad_sequences(new_url_sequences, maxlen=100)  # 시퀀스 길이를 모델의 입력 길이와 일치시킵니다.\n",
        "\n",
        "# 모델을 사용하여 예측\n",
        "predictions = model.predict(new_url_sequences)\n",
        "\n",
        "# 예측 결과를 레이블로 디코딩\n",
        "predicted_labels = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
        "\n",
        "# 예측된 레이블 출력\n",
        "print(\"Predicted Labels:\", predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUF2oQiIpgAS",
        "outputId": "8c779299-2eda-49cd-a071-7a3c95caa07e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4070/4070 [==============================] - 73s 18ms/step - loss: 0.1111 - accuracy: 0.9610\n",
            "Test accuracy: 96.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 URL 주소\n",
        "new_url = [\"https://www.youtube.com\"]  # 여기에 테스트하려는 URL 주소를 추가하세요\n",
        "\n",
        "# 텍스트 데이터를 시퀀스로 변환\n",
        "new_url_sequences = tokenizer.texts_to_sequences(new_url)\n",
        "new_url_sequences = pad_sequences(new_url_sequences, maxlen=100)  # 시퀀스 길이를 모델의 입력 길이와 일치시킵니다.\n",
        "\n",
        "# 모델을 사용하여 예측\n",
        "predictions = model.predict(new_url_sequences)\n",
        "\n",
        "# 예측 결과를 레이블로 디코딩\n",
        "predicted_labels = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
        "\n",
        "# 예측된 레이블 출력\n",
        "print(\"Predicted Labels:\", predicted_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogNjrYPEqyMz",
        "outputId": "34b5ba8f-ed3f-4271-a15d-16a5701961a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            "Predicted Labels: ['phishing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 새로운 URL 주소\n",
        "new_url = [\"https://www.naver.com\"]  # 여기에 테스트하려는 URL 주소를 추가하세요\n",
        "\n",
        "# 텍스트 데이터를 시퀀스로 변환\n",
        "new_url_sequences = tokenizer.texts_to_sequences(new_url)\n",
        "new_url_sequences = pad_sequences(new_url_sequences, maxlen=100)  # 시퀀스 길이를 모델의 입력 길이와 일치시킵니다.\n",
        "\n",
        "# 모델을 사용하여 확률 예측\n",
        "probabilities = model.predict(new_url_sequences)\n",
        "\n",
        "# \"phishing\" 레이블의 확률 출력\n",
        "phishing_probability = probabilities[0, label_encoder.transform([\"phishing\"])[0]]\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Phishing Probability: {phishing_probability * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NokN2QvzsgRz",
        "outputId": "2bc7ec93-58b7-4a6f-89e3-89093540c73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "Phishing Probability: 97.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0NB-NRXBsgqn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}